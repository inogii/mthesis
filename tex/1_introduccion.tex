Los sistemas de generación de audio basados en señales de EEG han emergido como una prometedora área de investigación debido a su capacidad para sintetizar audio a partir de señales cerebrales. Estos sistemas tienen aplicaciones en la comunicación asistida, la generación de habla para personas con discapacidades motoras y la interfaz cerebro-computadora, entre otros. Sin embargo, la generación de audio a partir de señales de EEG es un problema complejo que requiere la integración de técnicas de procesamiento de señales, aprendizaje profundo y neurociencia.

En este estudio, proponemos un sistema denominado EEG2Speech, un modelo de generación de habla condicionado a una señal de EEG. Para ello, se propone utilizar una arquitectura basada en un modelo de difusión latente de generación de audio condicionado a señales de EEG. Los modelos de difusión latente son una variante avanzada de los modelos de difusión que trabajan con representaciones latentes de los datos en lugar de con los datos originales. Esta representación latente es una forma comprimida de los datos originales que captura las características esenciales de los mismos, lo que permite una generación de muestras más eficiente computacionalmente.

El modelo EEG2Speech se basa en la arquitectura de AudioLDM, un sistema de generación de texto a audio que utiliza Modelos de Difusión Latente (LDM). AudioLDM se basa en el modelo de preentrenamiento contrastivo CLAP, que entrena un encoder de Audio y otro de Texto para que los embeddings de texto y audio de una misma pareja sean lo más similares posibles y los de parejas distintas sean lo más diferentes posibles. Durante la fase de entrenamiento, AudioLDM se condiciona únicamente con embeddings de audio para aprender a hacer denoising de las representaciones latentes de las señales de audio. Sin embargo, durante la inferencia, el modelo puede ser condicionado con embeddings de texto para guiar la generación de audio.

En el caso de EEG2Speech, se propone sustituir la pareja de encoders de Audio y Texto de CLAP por una pareja de encoders de EEG y Audio obtenida del proyecto brainmagick. Una vez modificada la arquitectura, se reentrena el modelo con el dataset empleado para el entrenamiento de brainmagick (brennan2019), y se evalúa su rendimiento en la generación de audio condicionado a señales de EEG.